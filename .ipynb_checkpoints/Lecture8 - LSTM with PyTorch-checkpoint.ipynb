{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Long Short-Term Memory Networks with PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model A: 1 Hidden Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Unroll 28 time steps\n",
    "    * Each step input size: 28 x 1\n",
    "    * Total per unroll: 28 x 28\n",
    "        * Feedforward Neural Network input size: 28 x 28\n",
    "* 1 Hidden Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Steps: \n",
    "\n",
    "<li> Step 1: Load Dataset\n",
    "<li> Step 2: Make Dataset Iterable\n",
    "<li> Step 3: Create Model Class\n",
    "<li> Step 4: Instantiate Model Class\n",
    "<li> Step 5: Instantiate Loss Class\n",
    "<li> Step 6: Instantiate Optimizer Class\n",
    "<li> Step 7: Train Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1: Load Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as dsets\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = dsets.MNIST(root = './data',\n",
    "                            train = True,\n",
    "                            transform = transforms.ToTensor(),\n",
    "                            download = True)\n",
    "\n",
    "test_dataset = dsets.MNIST(root = './data',\n",
    "                           train = False,\n",
    "                           transform = transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([60000, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset.data.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([60000])\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset.targets.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10000, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "print(test_dataset.data.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10000])\n"
     ]
    }
   ],
   "source": [
    "print(test_dataset.targets.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2: Make Dataset Iterable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "n_iters = 3000\n",
    "\n",
    "num_epochs = n_iters / (len(train_dataset) / batch_size)\n",
    "num_epochs = int(num_epochs)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                           batch_size=batch_size,\n",
    "                                           shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                        batch_size=batch_size,\n",
    "                                        shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3: Create Model Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMModel(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_dim, hidden_dim, layer_dim, output_dim):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        \n",
    "        # Hidden Dimensions\n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "        # Number of hidden layers\n",
    "        self.layer_dim = layer_dim\n",
    "        \n",
    "        # Building your LSTM\n",
    "        # batch_first = True causes input/output tensors to be of shape\n",
    "        # (batch_dim, seq_dim, feature_dim)\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, layer_dim, batch_first=True)\n",
    "        \n",
    "        # Readout layer\n",
    "        self.fn = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Initialize hidden state with zeroes\n",
    "        # (layer_dim, batch_size, hidden_dim)\n",
    "        h0 = Variable(torch.zeros(self.layer_dim, x.size(0), self.hidden_dim))\n",
    "        \n",
    "        # Initialize Cell State\n",
    "        c0 = Variable(torch.zeros(self.layer_dim, x.size(0), self.hidden_dim)) \n",
    "        \n",
    "        # 28 time-step\n",
    "        out, (hn, cn) = self.lstm(x, (h0,c0))\n",
    "        \n",
    "        # Input hidden state of the last time step\n",
    "        # out.size() ---> 100, 28, 100\n",
    "        # out[:, -1, :] ---> 100, 100 ---> just want last time step hidden states!\n",
    "        out = self.fn(out[:, -1, :])\n",
    "        # out.size() ---> 100, 10 \n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 4: Instantiate Model Class\n",
    "\n",
    "* 28 time steps\n",
    "    * Each time step: input dimension = 28\n",
    "* 1 Hidden Layer\n",
    "* MNIST 1-9 digits ----> output dimension = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = 28\n",
    "hidden_dim = 100\n",
    "layer_dim = 1\n",
    "output_dim = 10\n",
    "\n",
    "model = LSTMModel(input_dim, hidden_dim, layer_dim, output_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 5: Instantiate Loss Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 6: Instantiate Optimizer Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.1\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Parameters In-Depth**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(model.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([400, 28])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400])\n",
      "torch.Size([400])\n",
      "torch.Size([10, 100])\n",
      "torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(list(model.parameters()))):\n",
    "    print(list(model.parameters())[i].size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parameters\n",
    "- **Input** $\\rightarrow$ **Gates**\n",
    "    - $[400, 28] \\rightarrow w_1, w_3, w_5, w_7$\n",
    "    - $[400] \\rightarrow b_1, b_3, b_5, b_7$\n",
    "- **Hidden State** $\\rightarrow$ **Gates**\n",
    "    - $[400, 100] \\rightarrow w_2, w_4, w_6, w_8$\n",
    "    - $[400] \\rightarrow b_2, b_4, b_6, b_8$\n",
    "- **Hidden State** $\\rightarrow$ **Output**\n",
    "    - $[10, 100] \\rightarrow w_9$\n",
    "    - $[10] \\rightarrow b_9$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 7: Train Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process\n",
    "\n",
    "1. <b>Convert input/labels to variables</b>\n",
    "    * LSTM input: (1, 28)\n",
    "    * RNN input: (1, 28)\n",
    "    * CNN input: (1, 28, 28)\n",
    "    * Feedforward NN input: (1, 28*28)\n",
    "2. Clear gradient buffers\n",
    "3. Get output given inputs\n",
    "4. Get loss\n",
    "5. Get gradients w.r.t. parameters\n",
    "6. Update parameters using gradients\n",
    "    * parameters = parameters - leaarning_rate * parameter_gradients\n",
    "7. Repeat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations: 500, Loss: 2.2654316425323486, Accuracy: 18.0\n",
      "Iterations: 1000, Loss: 1.1688305139541626, Accuracy: 50.0\n",
      "Iterations: 1500, Loss: 0.4424925148487091, Accuracy: 82.0\n",
      "Iterations: 2000, Loss: 0.35868415236473083, Accuracy: 87.0\n",
      "Iterations: 2500, Loss: 0.24794839322566986, Accuracy: 93.0\n",
      "Iterations: 3000, Loss: 0.27900707721710205, Accuracy: 94.0\n"
     ]
    }
   ],
   "source": [
    "# Number of steps to unroll\\\n",
    "seq_dim = 28\n",
    "iter = 0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        \n",
    "        images = Variable(images.view(-1, seq_dim, input_dim))\n",
    "        labels = Variable(labels)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = model(images)\n",
    "        \n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        iter += 1\n",
    "        \n",
    "        if iter % 500 == 0:\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            \n",
    "            for images, labels in test_loader:\n",
    "                \n",
    "                images = Variable(images.view(-1, seq_dim, input_dim))\n",
    "                outputs = model(images)\n",
    "                \n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                \n",
    "                total += labels.size(0)\n",
    "                \n",
    "                correct += (predicted == labels).sum()\n",
    "                \n",
    "            accuracy = 100 * correct / total\n",
    "            \n",
    "            print('Iterations: {}, Loss: {}, Accuracy: {}'.format(iter, loss.data, accuracy.float()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "828"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model B: 2 Hidden Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Unroll 28 time steps\n",
    "    * Each step input size: 28 x 1\n",
    "    * Total per unroll: 28 x 28\n",
    "        * Feedforward Neural Network input size: 28 x 28\n",
    "* <b>2 Hidden Layers</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Steps: \n",
    "\n",
    "<li> Step 1: Load Dataset\n",
    "<li> Step 2: Make Dataset Iterable\n",
    "<li> Step 3: Create Model Class\n",
    "<li> Step 4: Instantiate Model Class\n",
    "<li> Step 5: Instantiate Loss Class\n",
    "<li> Step 6: Instantiate Optimizer Class\n",
    "<li> Step 7: Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "LSTMModel(\n",
      "  (lstm): LSTM(28, 100, num_layers=2, batch_first=True)\n",
      "  (fn): Linear(in_features=100, out_features=10, bias=True)\n",
      ")\n",
      "------------------------------------------------------------\n",
      "10\n",
      "------------------------------------------------------------\n",
      "torch.Size([400, 28])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400])\n",
      "torch.Size([400])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400])\n",
      "torch.Size([400])\n",
      "torch.Size([10, 100])\n",
      "torch.Size([10])\n",
      "------------------------------------------------------------\n",
      "------------------------------------------------------------\n",
      "Iterations: 500, Loss: 2.301187038421631, Accuracy: 12.0\n",
      "Iterations: 1000, Loss: 1.746108889579773, Accuracy: 37.0\n",
      "Iterations: 1500, Loss: 0.5666611194610596, Accuracy: 81.0\n",
      "Iterations: 2000, Loss: 0.3617479205131531, Accuracy: 91.0\n",
      "Iterations: 2500, Loss: 0.18505558371543884, Accuracy: 92.0\n",
      "Iterations: 3000, Loss: 0.06820815801620483, Accuracy: 95.0\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as dsets\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "'''\n",
    "STEP 1: LOAD DATASET\n",
    "'''\n",
    "train_dataset = dsets.MNIST(root = './data',\n",
    "                            train = True,\n",
    "                            transform = transforms.ToTensor(),\n",
    "                            download = True)\n",
    "\n",
    "test_dataset = dsets.MNIST(root = './data',\n",
    "                           train = False,\n",
    "                           transform = transforms.ToTensor())\n",
    "\n",
    "\n",
    "'''\n",
    "STEP 2: MAKE DATASET ITERABLE\n",
    "'''\n",
    "batch_size = 100\n",
    "n_iters = 3000\n",
    "\n",
    "num_epochs = n_iters / (len(train_dataset) / batch_size)\n",
    "num_epochs = int(num_epochs)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                           batch_size=batch_size,\n",
    "                                           shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                        batch_size=batch_size,\n",
    "                                        shuffle=False)\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "STEP 3: CREATE MODEL CLASS\n",
    "'''\n",
    "class LSTMModel(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_dim, hidden_dim, layer_dim, output_dim):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        \n",
    "        # Hidden Dimensions\n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "        # Number of hidden layers\n",
    "        self.layer_dim = layer_dim\n",
    "        \n",
    "        # Building your LSTM\n",
    "        # batch_first = True causes input/output tensors to be of shape\n",
    "        # (batch_dim, seq_dim, feature_dim)\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, layer_dim, batch_first=True)\n",
    "        \n",
    "        # Readout layer\n",
    "        self.fn = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Initialize hidden state with zeroes\n",
    "        # (layer_dim, batch_size, hidden_dim)\n",
    "        h0 = Variable(torch.zeros(self.layer_dim, x.size(0), self.hidden_dim))\n",
    "        \n",
    "        # Initialize Cell State\n",
    "        c0 = Variable(torch.zeros(self.layer_dim, x.size(0), self.hidden_dim)) \n",
    "        \n",
    "        # 28 time-step\n",
    "        out, (hn, cn) = self.lstm(x, (h0,c0))\n",
    "        \n",
    "        # Input hidden state of the last time step\n",
    "        # out.size() ---> 100, 28, 100\n",
    "        # out[:, -1, :] ---> 100, 100 ---> just want last time step hidden states!\n",
    "        out = self.fn(out[:, -1, :])\n",
    "        # out.size() ---> 100, 10 \n",
    "        return out\n",
    "    \n",
    "    \n",
    "    \n",
    "'''\n",
    "STEP 4: INSTANTIATE MODEL CLASS\n",
    "'''\n",
    "input_dim = 28\n",
    "hidden_dim = 100\n",
    "layer_dim = 2\n",
    "output_dim = 10\n",
    "\n",
    "model = LSTMModel(input_dim, hidden_dim, layer_dim, output_dim)\n",
    "\n",
    "\n",
    "print('-'*60)\n",
    "print(model)\n",
    "print('-'*60)\n",
    "print(len(list(model.parameters())))\n",
    "print('-'*60)\n",
    "for i in range(len(list(model.parameters()))):\n",
    "    print(list(model.parameters())[i].size())\n",
    "print('-'*60)\n",
    "print('-'*60)\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "STEP 5: INSTANTIATE LOSS CLASS\n",
    "'''\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "'''\n",
    "STEP 6: INSTANTIATE OPTIMIZER CLASS\n",
    "'''\n",
    "learning_rate = 0.1\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "\n",
    "'''\n",
    "STEP 7: TRAIN THE MODEL\n",
    "'''\n",
    "# Number of steps to unroll\\\n",
    "seq_dim = 28\n",
    "iter = 0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        \n",
    "        images = Variable(images.view(-1, seq_dim, input_dim))\n",
    "        labels = Variable(labels)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = model(images)\n",
    "        \n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        iter += 1\n",
    "        \n",
    "        if iter % 500 == 0:\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            \n",
    "            for images, labels in test_loader:\n",
    "                \n",
    "                images = Variable(images.view(-1, seq_dim, input_dim))\n",
    "                outputs = model(images)\n",
    "                \n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                \n",
    "                total += labels.size(0)\n",
    "                \n",
    "                correct += (predicted == labels).sum()\n",
    "                \n",
    "            accuracy = 100 * correct / total\n",
    "            \n",
    "            print('Iterations: {}, Loss: {}, Accuracy: {}'.format(iter, loss.data, accuracy.float()))\n",
    "\n",
    "            \n",
    "            \n",
    "print('-'*60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model C: 3 Hidden Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Unroll 28 time steps\n",
    "    * Each step input size: 28 x 1\n",
    "    * Total per unroll: 28 x 28\n",
    "        * Feedforward Neural Network input size: 28 x 28\n",
    "* <b>3 Hidden Layers</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Steps: \n",
    "\n",
    "<li> Step 1: Load Dataset\n",
    "<li> Step 2: Make Dataset Iterable\n",
    "<li> Step 3: Create Model Class\n",
    "<li> Step 4: Instantiate Model Class\n",
    "<li> Step 5: Instantiate Loss Class\n",
    "<li> Step 6: Instantiate Optimizer Class\n",
    "<li> Step 7: Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "LSTMModel(\n",
      "  (lstm): LSTM(28, 100, num_layers=3, batch_first=True)\n",
      "  (fn): Linear(in_features=100, out_features=10, bias=True)\n",
      ")\n",
      "------------------------------------------------------------\n",
      "14\n",
      "------------------------------------------------------------\n",
      "torch.Size([400, 28])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400])\n",
      "torch.Size([400])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400])\n",
      "torch.Size([400])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400])\n",
      "torch.Size([400])\n",
      "torch.Size([10, 100])\n",
      "torch.Size([10])\n",
      "------------------------------------------------------------\n",
      "------------------------------------------------------------\n",
      "Iterations: 500, Loss: 2.293963670730591, Accuracy: 11.0\n",
      "Iterations: 1000, Loss: 2.295689344406128, Accuracy: 11.0\n",
      "Iterations: 1500, Loss: 2.1494925022125244, Accuracy: 21.0\n",
      "Iterations: 2000, Loss: 1.1335668563842773, Accuracy: 63.0\n",
      "Iterations: 2500, Loss: 0.6934176087379456, Accuracy: 81.0\n",
      "Iterations: 3000, Loss: 0.19931282103061676, Accuracy: 89.0\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as dsets\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "'''\n",
    "STEP 1: LOAD DATASET\n",
    "'''\n",
    "train_dataset = dsets.MNIST(root = './data',\n",
    "                            train = True,\n",
    "                            transform = transforms.ToTensor(),\n",
    "                            download = True)\n",
    "\n",
    "test_dataset = dsets.MNIST(root = './data',\n",
    "                           train = False,\n",
    "                           transform = transforms.ToTensor())\n",
    "\n",
    "\n",
    "'''\n",
    "STEP 2: MAKE DATASET ITERABLE\n",
    "'''\n",
    "batch_size = 100\n",
    "n_iters = 3000\n",
    "\n",
    "num_epochs = n_iters / (len(train_dataset) / batch_size)\n",
    "num_epochs = int(num_epochs)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                           batch_size=batch_size,\n",
    "                                           shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                        batch_size=batch_size,\n",
    "                                        shuffle=False)\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "STEP 3: CREATE MODEL CLASS\n",
    "'''\n",
    "class LSTMModel(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_dim, hidden_dim, layer_dim, output_dim):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        \n",
    "        # Hidden Dimensions\n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "        # Number of hidden layers\n",
    "        self.layer_dim = layer_dim\n",
    "        \n",
    "        # Building your LSTM\n",
    "        # batch_first = True causes input/output tensors to be of shape\n",
    "        # (batch_dim, seq_dim, feature_dim)\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, layer_dim, batch_first=True)\n",
    "        \n",
    "        # Readout layer\n",
    "        self.fn = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Initialize hidden state with zeroes\n",
    "        # (layer_dim, batch_size, hidden_dim)\n",
    "        h0 = Variable(torch.zeros(self.layer_dim, x.size(0), self.hidden_dim))\n",
    "        \n",
    "        # Initialize Cell State\n",
    "        c0 = Variable(torch.zeros(self.layer_dim, x.size(0), self.hidden_dim)) \n",
    "        \n",
    "        # 28 time-step\n",
    "        out, (hn, cn) = self.lstm(x, (h0,c0))\n",
    "        \n",
    "        # Input hidden state of the last time step\n",
    "        # out.size() ---> 100, 28, 100\n",
    "        # out[:, -1, :] ---> 100, 100 ---> just want last time step hidden states!\n",
    "        out = self.fn(out[:, -1, :])\n",
    "        # out.size() ---> 100, 10 \n",
    "        return out\n",
    "    \n",
    "    \n",
    "    \n",
    "'''\n",
    "STEP 4: INSTANTIATE MODEL CLASS\n",
    "'''\n",
    "input_dim = 28\n",
    "hidden_dim = 100\n",
    "layer_dim = 3\n",
    "output_dim = 10\n",
    "\n",
    "model = LSTMModel(input_dim, hidden_dim, layer_dim, output_dim)\n",
    "\n",
    "print('-'*60)\n",
    "print(model)\n",
    "print('-'*60)\n",
    "print(len(list(model.parameters())))\n",
    "print('-'*60)\n",
    "for i in range(len(list(model.parameters()))):\n",
    "    print(list(model.parameters())[i].size())\n",
    "print('-'*60)\n",
    "print('-'*60)\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "STEP 5: INSTANTIATE LOSS CLASS\n",
    "'''\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "'''\n",
    "STEP 6: INSTANTIATE OPTIMIZER CLASS\n",
    "'''\n",
    "learning_rate = 0.1\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "\n",
    "'''\n",
    "STEP 7: TRAIN THE MODEL\n",
    "'''\n",
    "# Number of steps to unroll\\\n",
    "seq_dim = 28\n",
    "iter = 0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        \n",
    "        images = Variable(images.view(-1, seq_dim, input_dim))\n",
    "        labels = Variable(labels)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = model(images)\n",
    "        \n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        iter += 1\n",
    "        \n",
    "        if iter % 500 == 0:\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            \n",
    "            for images, labels in test_loader:\n",
    "                \n",
    "                images = Variable(images.view(-1, seq_dim, input_dim))\n",
    "                outputs = model(images)\n",
    "                \n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                \n",
    "                total += labels.size(0)\n",
    "                \n",
    "                correct += (predicted == labels).sum()\n",
    "                \n",
    "            accuracy = 100 * correct / total\n",
    "            \n",
    "            print('Iterations: {}, Loss: {}, Accuracy: {}'.format(iter, loss.data, accuracy.float()))\n",
    "\n",
    "            \n",
    "            \n",
    "print('-'*60)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison with RNN\n",
    "\n",
    "|     Model A RNN    |     Model B RNN    |   Model C RNN      |\n",
    "|--------------------|--------------------|--------------------|\n",
    "|   ReLU             |  ReLU              |  TanH              |\n",
    "|  1 Hidden Layer    |  2 Hidden Layers   |  2 Hidden Layers   |\n",
    "|  100 Hidden Units  |  100 Hidden Units  |  100 Hidden Units  |\n",
    "|     > 86 %         |      > 95 %        |       > 95 %       |\n",
    "\n",
    "|     Model A LSTM   |     Model B LSTM   |   Model C LSTM     |\n",
    "|--------------------|--------------------|--------------------|\n",
    "|  1 Hidden Layer    |  2 Hidden Layers   |  3 Hidden Layers   |\n",
    "|  100 Hidden Units  |  100 Hidden Units  |  100 Hidden Units  |\n",
    "|    > 94 %          |     > 95 %         |      89 %          |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep Learning\n",
    "\n",
    "- 2 ways to expand a Long short-term memory network\n",
    "    - More Hidden Units\n",
    "        - $(o, i, f, g)$ gates\n",
    "    - More Hidden layers\n",
    "- Cons\n",
    "    - Need a larger dataset\n",
    "        - Curse of Dimensionality\n",
    "    - Does not necessarily mean higher accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Long Short-Term Memory Networks with PyTorch (GPU)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model B: 2 Hidden Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Unroll 28 time steps\n",
    "    * Each step input size: 28 x 1\n",
    "    * Total per unroll: 28 x 28\n",
    "        * Feedforward Neural Network input size: 28 x 28\n",
    "* <b>2 Hidden Layers</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Steps: \n",
    "\n",
    "<li> Step 1: Load Dataset\n",
    "<li> Step 2: Make Dataset Iterable\n",
    "<li> <b>Step 3: Create Model Class</b>\n",
    "<li> <b>Step 4: Instantiate Model Class</b>\n",
    "<li> Step 5: Instantiate Loss Class\n",
    "<li> Step 6: Instantiate Optimizer Class\n",
    "<li> <b>Step 7: Train Model</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "LSTMModel(\n",
      "  (lstm): LSTM(28, 100, num_layers=2, batch_first=True)\n",
      "  (fn): Linear(in_features=100, out_features=10, bias=True)\n",
      ")\n",
      "------------------------------------------------------------\n",
      "10\n",
      "------------------------------------------------------------\n",
      "torch.Size([400, 28])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400])\n",
      "torch.Size([400])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400])\n",
      "torch.Size([400])\n",
      "torch.Size([10, 100])\n",
      "torch.Size([10])\n",
      "------------------------------------------------------------\n",
      "------------------------------------------------------------\n",
      "Iterations: 500, Loss: 2.301875352859497, Accuracy: 12.0\n",
      "Iterations: 1000, Loss: 1.8230276107788086, Accuracy: 39.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as dsets\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "'''\n",
    "STEP 1: LOAD DATASET\n",
    "'''\n",
    "train_dataset = dsets.MNIST(root = './data',\n",
    "                            train = True,\n",
    "                            transform = transforms.ToTensor(),\n",
    "                            download = True)\n",
    "\n",
    "test_dataset = dsets.MNIST(root = './data',\n",
    "                           train = False,\n",
    "                           transform = transforms.ToTensor())\n",
    "\n",
    "\n",
    "'''\n",
    "STEP 2: MAKE DATASET ITERABLE\n",
    "'''\n",
    "batch_size = 100\n",
    "n_iters = 3000\n",
    "\n",
    "num_epochs = n_iters / (len(train_dataset) / batch_size)\n",
    "num_epochs = int(num_epochs)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                           batch_size=batch_size,\n",
    "                                           shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                        batch_size=batch_size,\n",
    "                                        shuffle=False)\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "STEP 3: CREATE MODEL CLASS\n",
    "'''\n",
    "class LSTMModel(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_dim, hidden_dim, layer_dim, output_dim):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        \n",
    "        # Hidden Dimensions\n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "        # Number of hidden layers\n",
    "        self.layer_dim = layer_dim\n",
    "        \n",
    "        # Building your LSTM\n",
    "        # batch_first = True causes input/output tensors to be of shape\n",
    "        # (batch_dim, seq_dim, feature_dim)\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, layer_dim, batch_first=True)\n",
    "        \n",
    "        # Readout layer\n",
    "        self.fn = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Initialize hidden state with zeroes\n",
    "        # (layer_dim, batch_size, hidden_dim)\n",
    "        if torch.cuda.is_available():\n",
    "            h0 = Variable(torch.zeros(self.layer_dim, x.size(0), self.hidden_dim).cuda())\n",
    "            # Initialize Cell State\n",
    "            c0 = Variable(torch.zeros(self.layer_dim, x.size(0), self.hidden_dim).cuda()) \n",
    "        else:\n",
    "            h0 = Variable(torch.zeros(self.layer_dim, x.size(0), self.hidden_dim))\n",
    "            # Initialize Cell State\n",
    "            c0 = Variable(torch.zeros(self.layer_dim, x.size(0), self.hidden_dim)) \n",
    "        \n",
    "\n",
    "        \n",
    "        # 28 time-step\n",
    "        out, (hn, cn) = self.lstm(x, (h0,c0))\n",
    "        \n",
    "        # Input hidden state of the last time step\n",
    "        # out.size() ---> 100, 28, 100\n",
    "        # out[:, -1, :] ---> 100, 100 ---> just want last time step hidden states!\n",
    "        out = self.fn(out[:, -1, :])\n",
    "        # out.size() ---> 100, 10 \n",
    "        return out\n",
    "    \n",
    "    \n",
    "    \n",
    "'''\n",
    "STEP 4: INSTANTIATE MODEL CLASS\n",
    "'''\n",
    "input_dim = 28\n",
    "hidden_dim = 100\n",
    "layer_dim = 2\n",
    "output_dim = 10\n",
    "\n",
    "model = LSTMModel(input_dim, hidden_dim, layer_dim, output_dim)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    model.cuda()\n",
    "\n",
    "print('-'*60)\n",
    "print(model)\n",
    "print('-'*60)\n",
    "print(len(list(model.parameters())))\n",
    "print('-'*60)\n",
    "for i in range(len(list(model.parameters()))):\n",
    "    print(list(model.parameters())[i].size())\n",
    "print('-'*60)\n",
    "print('-'*60)\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "STEP 5: INSTANTIATE LOSS CLASS\n",
    "'''\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "'''\n",
    "STEP 6: INSTANTIATE OPTIMIZER CLASS\n",
    "'''\n",
    "learning_rate = 0.1\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "\n",
    "'''\n",
    "STEP 7: TRAIN THE MODEL\n",
    "'''\n",
    "# Number of steps to unroll\\\n",
    "seq_dim = 28\n",
    "iter = 0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        \n",
    "        if torch.cuda.is_available():\n",
    "            images = Variable(images.view(-1, seq_dim, input_dim).cuda())\n",
    "            labels = Variable(labels.cuda())\n",
    "        else:\n",
    "            images = Variable(images.view(-1, seq_dim, input_dim))\n",
    "            labels = Variable(labels)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = model(images)\n",
    "        \n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        iter += 1\n",
    "        \n",
    "        if iter % 500 == 0:\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            \n",
    "            for images, labels in test_loader:\n",
    "                if torch.cuda.is_available():\n",
    "                    images = Variable(images.view(-1, seq_dim, input_dim).cuda())\n",
    "                else:\n",
    "                    images = Variable(images.view(-1, seq_dim, input_dim))\n",
    "                    \n",
    "                outputs = model(images)\n",
    "                \n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                \n",
    "                total += labels.size(0)\n",
    "                \n",
    "                if torch.cuda.is_available():\n",
    "                    correct += (predicted.cpu() == labels.cpu()).sum()\n",
    "                else:\n",
    "                    correct += (predicted == labels).sum()\n",
    "                \n",
    "            accuracy = 100 * correct / total\n",
    "            \n",
    "            print('Iterations: {}, Loss: {}, Accuracy: {}'.format(iter, loss.data, accuracy.float()))\n",
    "\n",
    "            \n",
    "            \n",
    "print('-'*60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model = True\n",
    "if save_model is True:\n",
    "    # saving only params\n",
    "    torch.save(model.state_dict(), 'Models/LSTMPytorch.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
