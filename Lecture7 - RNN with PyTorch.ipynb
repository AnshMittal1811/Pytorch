{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recurrent Neural Network with Pytorch "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model A: 1 Hidden Layer (ReLU)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Unroll 28 time steps\n",
    "    * Each step input size: 28 x 1\n",
    "    * Total per unroll: 28 x 28\n",
    "        * Feedforward Neural Network input size: 28 x 28\n",
    "* 1 Hidden Layer\n",
    "* ReLU Activation Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Steps: \n",
    "\n",
    "<li> Step 1: Load Dataset\n",
    "<li> Step 2: Make Dataset Iterable\n",
    "<li> Step 3: Create Model Class\n",
    "<li> Step 4: Instantiate Model Class\n",
    "<li> Step 5: Instantiate Loss Class\n",
    "<li> Step 6: Instantiate Optimizer Class\n",
    "<li> Step 7: Train Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1: Load Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as dsets\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = dsets.MNIST(root = './data',\n",
    "                            train = True,\n",
    "                            transform = transforms.ToTensor(),\n",
    "                            download = True)\n",
    "\n",
    "test_dataset = dsets.MNIST(root = './data',\n",
    "                           train = False,\n",
    "                           transform = transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([60000, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset.data.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([60000])\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset.targets.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10000, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "print(test_dataset.data.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10000])\n"
     ]
    }
   ],
   "source": [
    "print(test_dataset.targets.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2: Make Dataset Iterable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "n_iters = 3000\n",
    "\n",
    "num_epochs = n_iters / (len(train_dataset) / batch_size)\n",
    "num_epochs = int(num_epochs)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                           batch_size=batch_size,\n",
    "                                           shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                        batch_size=batch_size,\n",
    "                                        shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3: Create Model Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNModel(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_dim, hidden_dim, layer_dim, output_dim):\n",
    "        super(RNNModel, self).__init__()\n",
    "        # Hidden Dimensions\n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "        # Number of hidden layers\n",
    "        self.layer_dim = layer_dim\n",
    "        \n",
    "        # Building your RNN\n",
    "        # batch_first = True causes input/output tensors to be of shape\n",
    "        # (batch_dim, seq_dim, input_dim)\n",
    "        self.rnn = nn.RNN(input_dim, hidden_dim, layer_dim, batch_first=True, nonlinearity = 'relu')\n",
    "        \n",
    "        # Readout layer\n",
    "        self.fn = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Initialize hidden state with zeroes\n",
    "        # (layer_dim, batch_size, hidden_dim)\n",
    "        h0 = Variable(torch.zeros(self.layer_dim, x.size(0), self.hidden_dim))\n",
    "        \n",
    "        # One time-step\n",
    "        out, hn = self.rnn(x, h0)\n",
    "        \n",
    "        # Input hidden state of the last time step\n",
    "        # out.size() ---> 100, 28, 100\n",
    "        # out[:, -1, :] ---> 100, 100 ---> just want last time step hidden states!\n",
    "        out = self.fn(out[:, -1, :])\n",
    "        # out.size() ---> 100, 10 \n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 4: Instantiate Model Class\n",
    "\n",
    "* 28 time steps\n",
    "    * Each time step: input dimension = 28\n",
    "* 1 Hidden Layer\n",
    "* MNIST 1-9 digits ----> output dimension = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = 28\n",
    "hidden_dim = 100\n",
    "layer_dim = 1\n",
    "output_dim = 10\n",
    "\n",
    "model = RNNModel(input_dim, hidden_dim, layer_dim, output_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 5: Instantiate Loss Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 6: Instantiate Optimizer Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.1\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Parameters In-Depth**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(model.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 28])\n",
      "torch.Size([100])\n",
      "torch.Size([100, 100])\n",
      "torch.Size([100])\n",
      "torch.Size([10, 100])\n",
      "torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "# Input --> Hidden (A1)\n",
    "print(list(model.parameters())[0].size())\n",
    "# Input --> Hidden Bias (B1)\n",
    "print(list(model.parameters())[2].size())\n",
    "\n",
    "# Hidden --> Hidden (A3)\n",
    "print(list(model.parameters())[1].size())\n",
    "# Hidden --> Hidden Bias (B3)\n",
    "print(list(model.parameters())[3].size())\n",
    "\n",
    "# Hidden -> Output (A2)\n",
    "print(list(model.parameters())[4].size())\n",
    "# Hidden -> Output Bias (B2)\n",
    "print(list(model.parameters())[5].size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 7: Train Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process\n",
    "\n",
    "1. <b>Convert input/labels to variables</b>\n",
    "    * RNN input: (1, 28)\n",
    "    * CNN input: (1, 28, 28)\n",
    "    * Feedforward NN input: (1, 28*28)\n",
    "2. Clear gradient buffers\n",
    "3. Get output given inputs\n",
    "4. Get loss\n",
    "5. Get gradients w.r.t. parameters\n",
    "6. Update parameters using gradients\n",
    "    * parameters = parameters - leaarning_rate * parameter_gradients\n",
    "7. Repeat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations: 500, Loss: 1.1717265844345093, Accuracy: 59.0\n",
      "Iterations: 1000, Loss: 1.3896496295928955, Accuracy: 58.0\n",
      "Iterations: 1500, Loss: 0.6873026490211487, Accuracy: 70.0\n",
      "Iterations: 2000, Loss: 1.009582281112671, Accuracy: 71.0\n",
      "Iterations: 2500, Loss: 0.4830789268016815, Accuracy: 86.0\n",
      "Iterations: 3000, Loss: 0.32755807042121887, Accuracy: 86.0\n"
     ]
    }
   ],
   "source": [
    "# Number of steps to unroll\\\n",
    "seq_dim = 28\n",
    "iter = 0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        \n",
    "        images = Variable(images.view(-1, seq_dim, input_dim))\n",
    "        labels = Variable(labels)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = model(images)\n",
    "        \n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        iter += 1\n",
    "        \n",
    "        if iter % 500 == 0:\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            \n",
    "            for images, labels in test_loader:\n",
    "                \n",
    "                images = Variable(images.view(-1, seq_dim, input_dim))\n",
    "                outputs = model(images)\n",
    "                \n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                \n",
    "                total += labels.size(0)\n",
    "                \n",
    "                correct += (predicted == labels).sum()\n",
    "                \n",
    "            accuracy = 100 * correct / total\n",
    "            \n",
    "            print('Iterations: {}, Loss: {}, Accuracy: {}'.format(iter, loss.data, accuracy.float()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model B: 2 Hidden Layer (ReLU)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Unroll 28 time steps\n",
    "    * Each step input size: 28 x 1\n",
    "    * Total per unroll: 28 x 28\n",
    "        * Feedforward Neural Network input size: 28 x 28\n",
    "* <b>2 Hidden Layer</b>\n",
    "* ReLU Activation Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Steps: \n",
    "\n",
    "<li> Step 1: Load Dataset\n",
    "<li> Step 2: Make Dataset Iterable\n",
    "<li> Step 3: Create Model Class\n",
    "<li> <b>Step 4: Instantiate Model Class </b>\n",
    "<li> Step 5: Instantiate Loss Class\n",
    "<li> Step 6: Instantiate Optimizer Class\n",
    "<li> Step 7: Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNNModel(\n",
      "  (rnn): RNN(28, 100, num_layers=2, batch_first=True)\n",
      "  (fn): Linear(in_features=100, out_features=10, bias=True)\n",
      ")\n",
      "------------------------------------------------------------\n",
      "10\n",
      "torch.Size([100, 28])\n",
      "torch.Size([100, 100])\n",
      "torch.Size([100])\n",
      "torch.Size([100])\n",
      "torch.Size([100, 100])\n",
      "torch.Size([100, 100])\n",
      "torch.Size([100])\n",
      "torch.Size([100])\n",
      "torch.Size([10, 100])\n",
      "torch.Size([10])\n",
      "------------------------------------------------------------\n",
      "Iterations: 500, Loss: 1.169751763343811, Accuracy: 62.0\n",
      "Iterations: 1000, Loss: 0.6962988376617432, Accuracy: 64.0\n",
      "Iterations: 1500, Loss: 0.2189740240573883, Accuracy: 92.0\n",
      "Iterations: 2000, Loss: 0.15934990346431732, Accuracy: 94.0\n",
      "Iterations: 2500, Loss: 0.1623079627752304, Accuracy: 95.0\n",
      "Iterations: 3000, Loss: 0.13616520166397095, Accuracy: 95.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as dsets\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "'''\n",
    "STEP 1: LOAD DATASET\n",
    "'''\n",
    "train_dataset = dsets.MNIST(root = './data',\n",
    "                            train = True,\n",
    "                            transform = transforms.ToTensor(),\n",
    "                            download = True)\n",
    "\n",
    "test_dataset = dsets.MNIST(root = './data',\n",
    "                           train = False,\n",
    "                           transform = transforms.ToTensor())\n",
    "\n",
    "\n",
    "'''\n",
    "STEP 2: MAKE SATASET ITERABLE\n",
    "'''\n",
    "batch_size = 100\n",
    "n_iters = 3000\n",
    "\n",
    "num_epochs = n_iters / (len(train_dataset) / batch_size)\n",
    "num_epochs = int(num_epochs)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                           batch_size=batch_size,\n",
    "                                           shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                        batch_size=batch_size,\n",
    "                                        shuffle=False)\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "STEP 3: CREATE MODEL CLASS\n",
    "'''\n",
    "class RNNModel(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_dim, hidden_dim, layer_dim, output_dim):\n",
    "        super(RNNModel, self).__init__()\n",
    "        # Hidden Dimensions\n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "        # Number of hidden layers\n",
    "        self.layer_dim = layer_dim\n",
    "        \n",
    "        # Building your RNN\n",
    "        # batch_first = True causes input/output tensors to be of shape\n",
    "        # (batch_dim, seq_dim, input_dim)\n",
    "        self.rnn = nn.RNN(input_dim, hidden_dim, layer_dim, batch_first=True, nonlinearity = 'relu')\n",
    "        \n",
    "        # Readout layer\n",
    "        self.fn = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Initialize hidden state with zeroes\n",
    "        h0 = Variable(torch.zeros(self.layer_dim, x.size(0), self.hidden_dim))\n",
    "        \n",
    "        # One time-step\n",
    "        out, hn = self.rnn(x, h0)\n",
    "        \n",
    "        # Input hidden state of the last time step\n",
    "        # out.size() ---> 100, 28, 100\n",
    "        # out[:, -1, :] ---> 100, 100 ---> just want last time step hidden states!\n",
    "        out = self.fn(out[:, -1, :])\n",
    "        # out.size() ---> 100, 10 \n",
    "        return out\n",
    "   \n",
    "\n",
    "\n",
    "'''\n",
    "STEP 4: INSTANTIATE MODEL CLASS\n",
    "'''\n",
    "input_dim = 28\n",
    "hidden_dim = 100\n",
    "layer_dim = 2\n",
    "output_dim = 10\n",
    "\n",
    "model = RNNModel(input_dim, hidden_dim, layer_dim, output_dim)\n",
    "\n",
    "# PRINTING MODEL AND PARAMETERS\n",
    "print(model)\n",
    "print('-'*60)\n",
    "print(len(list(model.parameters())))\n",
    "for i in range(len(list(model.parameters()))):\n",
    "    print(list(model.parameters())[i].size())\n",
    "print('-'*60)\n",
    "\n",
    "\n",
    "'''\n",
    "STEP 5: INSTANTIATE LOSS CLASS\n",
    "'''\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "'''\n",
    "STEP 6: INSTANTIATE OPTIMIZER CLASS\n",
    "'''\n",
    "learning_rate = 0.1\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "STEP 7: TRAIN THE MODEL\n",
    "'''\n",
    "# Number of steps to unroll\\\n",
    "seq_dim = 28\n",
    "iter = 0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        \n",
    "        images = Variable(images.view(-1, seq_dim, input_dim))\n",
    "        labels = Variable(labels)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = model(images)\n",
    "        \n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        iter += 1\n",
    "        \n",
    "        if iter % 500 == 0:\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            \n",
    "            for images, labels in test_loader:\n",
    "                \n",
    "                images = Variable(images.view(-1, seq_dim, input_dim))\n",
    "                outputs = model(images)\n",
    "                \n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                \n",
    "                total += labels.size(0)\n",
    "                \n",
    "                correct += (predicted == labels).sum()\n",
    "                \n",
    "            accuracy = 100 * correct / total\n",
    "            print('Iterations: {}, Loss: {}, Accuracy: {}'.format(iter, loss.data, accuracy.float()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model C: 2 Hidden Layer (TanH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Unroll 28 time steps\n",
    "    * Each step input size: 28 x 1\n",
    "    * Total per unroll: 28 x 28\n",
    "        * Feedforward Neural Network input size: 28 x 28\n",
    "* <b>2 Hidden Layer</b>\n",
    "* ReLU Activation Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Steps: \n",
    "\n",
    "<li> Step 1: Load Dataset\n",
    "<li> Step 2: Make Dataset Iterable\n",
    "<li> <b>Step 3: Create Model Class </b>\n",
    "<li> Step 4: Instantiate Model Class\n",
    "<li> Step 5: Instantiate Loss Class\n",
    "<li> Step 6: Instantiate Optimizer Class\n",
    "<li> Step 7: Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNNModel(\n",
      "  (rnn): RNN(28, 100, num_layers=2, batch_first=True)\n",
      "  (fn): Linear(in_features=100, out_features=10, bias=True)\n",
      ")\n",
      "------------------------------------------------------------\n",
      "10\n",
      "torch.Size([100, 28])\n",
      "torch.Size([100, 100])\n",
      "torch.Size([100])\n",
      "torch.Size([100])\n",
      "torch.Size([100, 100])\n",
      "torch.Size([100, 100])\n",
      "torch.Size([100])\n",
      "torch.Size([100])\n",
      "torch.Size([10, 100])\n",
      "torch.Size([10])\n",
      "------------------------------------------------------------\n",
      "Iterations: 500, Loss: 0.5385576486587524, Accuracy: 83.0\n",
      "Iterations: 1000, Loss: 0.3958626985549927, Accuracy: 91.0\n",
      "Iterations: 1500, Loss: 0.1738455891609192, Accuracy: 93.0\n",
      "Iterations: 2000, Loss: 0.13413047790527344, Accuracy: 95.0\n",
      "Iterations: 2500, Loss: 0.3107783794403076, Accuracy: 95.0\n",
      "Iterations: 3000, Loss: 0.16378650069236755, Accuracy: 94.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as dsets\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "'''\n",
    "STEP 1: LOAD DATASET\n",
    "'''\n",
    "train_dataset = dsets.MNIST(root = './data',\n",
    "                            train = True,\n",
    "                            transform = transforms.ToTensor(),\n",
    "                            download = True)\n",
    "\n",
    "test_dataset = dsets.MNIST(root = './data',\n",
    "                           train = False,\n",
    "                           transform = transforms.ToTensor())\n",
    "\n",
    "\n",
    "'''\n",
    "STEP 2: MAKE SATASET ITERABLE\n",
    "'''\n",
    "batch_size = 100\n",
    "n_iters = 3000\n",
    "\n",
    "num_epochs = n_iters / (len(train_dataset) / batch_size)\n",
    "num_epochs = int(num_epochs)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                           batch_size=batch_size,\n",
    "                                           shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                        batch_size=batch_size,\n",
    "                                        shuffle=False)\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "STEP 3: CREATE MODEL CLASS\n",
    "'''\n",
    "class RNNModel(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_dim, hidden_dim, layer_dim, output_dim):\n",
    "        super(RNNModel, self).__init__()\n",
    "        # Hidden Dimensions\n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "        # Number of hidden layers\n",
    "        self.layer_dim = layer_dim\n",
    "        \n",
    "        # Building your RNN\n",
    "        # batch_first = True causes input/output tensors to be of shape\n",
    "        # (batch_dim, seq_dim, input_dim)\n",
    "        self.rnn = nn.RNN(input_dim, hidden_dim, layer_dim, batch_first=True, nonlinearity = 'tanh')\n",
    "        \n",
    "        # Readout layer\n",
    "        self.fn = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Initialize hidden state with zeroes\n",
    "        h0 = Variable(torch.zeros(self.layer_dim, x.size(0), self.hidden_dim))\n",
    "        \n",
    "        # One time-step\n",
    "        out, hn = self.rnn(x, h0)\n",
    "        \n",
    "        # Input hidden state of the last time step\n",
    "        # out.size() ---> 100, 28, 100\n",
    "        # out[:, -1, :] ---> 100, 100 ---> just want last time step hidden states!\n",
    "        out = self.fn(out[:, -1, :])\n",
    "        # out.size() ---> 100, 10 \n",
    "        return out\n",
    "   \n",
    "\n",
    "\n",
    "'''\n",
    "STEP 4: INSTANTIATE MODEL CLASS\n",
    "'''\n",
    "input_dim = 28\n",
    "hidden_dim = 100\n",
    "layer_dim = 2\n",
    "output_dim = 10\n",
    "\n",
    "model = RNNModel(input_dim, hidden_dim, layer_dim, output_dim)\n",
    "\n",
    "# PRINTING MODEL AND PARAMETERS\n",
    "print(model)\n",
    "print('-'*60)\n",
    "print(len(list(model.parameters())))\n",
    "for i in range(len(list(model.parameters()))):\n",
    "    print(list(model.parameters())[i].size())\n",
    "print('-'*60)\n",
    "\n",
    "\n",
    "'''\n",
    "STEP 5: INSTANTIATE LOSS CLASS\n",
    "'''\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "'''\n",
    "STEP 6: INSTANTIATE OPTIMIZER CLASS\n",
    "'''\n",
    "learning_rate = 0.1\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "STEP 7: TRAIN THE MODEL\n",
    "'''\n",
    "# Number of steps to unroll\\\n",
    "seq_dim = 28\n",
    "iter = 0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        \n",
    "        images = Variable(images.view(-1, seq_dim, input_dim))\n",
    "        labels = Variable(labels)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = model(images)\n",
    "        \n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        iter += 1\n",
    "        \n",
    "        if iter % 500 == 0:\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            \n",
    "            for images, labels in test_loader:\n",
    "                \n",
    "                images = Variable(images.view(-1, seq_dim, input_dim))\n",
    "                outputs = model(images)\n",
    "                \n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                \n",
    "                total += labels.size(0)\n",
    "                \n",
    "                correct += (predicted == labels).sum()\n",
    "                \n",
    "            accuracy = 100 * correct / total\n",
    "            \n",
    "            print('Iterations: {}, Loss: {}, Accuracy: {}'.format(iter, loss.data, accuracy.float()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary of Results\n",
    "\n",
    "|     Model A        |     Model B        |   Model C          |\n",
    "|--------------------|--------------------|--------------------|\n",
    "|   ReLU             |  ReLU              |  TanH              |\n",
    "|  1 Hidden Layer    |  2 Hidden Layers   |  2 Hidden Layers   |\n",
    "|  100 Hidden Units  |  100 Hidden Units  |  100 Hidden Units  |\n",
    "|     > 86 %         |      > 95 %        |       > 95 %       |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deep Learning \n",
    "\n",
    "* 2 ways to expand a recurrent neural network\n",
    "    * More non-linear activation units (neurons)\n",
    "    * More Hidden Layers\n",
    "* Cons\n",
    "    * Need a Larger Dataset\n",
    "        * Curse of Dimensionality\n",
    "    * Does not necessarily mean higher accuracy\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recurrent Neural Network with Pytorch (GPU)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Steps: \n",
    "\n",
    "<li> Step 1: Load Dataset\n",
    "<li> Step 2: Make Dataset Iterable\n",
    "<li> <b>Step 3: Create Model Class </b>\n",
    "<li> Step 4: Instantiate Model Class\n",
    "<li> Step 5: Instantiate Loss Class\n",
    "<li> Step 6: Instantiate Optimizer Class\n",
    "<li> Step 7: Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNNModel(\n",
      "  (rnn): RNN(28, 100, num_layers=2, batch_first=True)\n",
      "  (fn): Linear(in_features=100, out_features=10, bias=True)\n",
      ")\n",
      "------------------------------------------------------------\n",
      "10\n",
      "torch.Size([100, 28])\n",
      "torch.Size([100, 100])\n",
      "torch.Size([100])\n",
      "torch.Size([100])\n",
      "torch.Size([100, 100])\n",
      "torch.Size([100, 100])\n",
      "torch.Size([100])\n",
      "torch.Size([100])\n",
      "torch.Size([10, 100])\n",
      "torch.Size([10])\n",
      "------------------------------------------------------------\n",
      "Iterations: 500, Loss: 0.4747331142425537, Accuracy: 82.0\n",
      "Iterations: 1000, Loss: 0.8292064666748047, Accuracy: 81.0\n",
      "Iterations: 1500, Loss: 0.27577075362205505, Accuracy: 93.0\n",
      "Iterations: 2000, Loss: 0.2377377301454544, Accuracy: 94.0\n",
      "Iterations: 2500, Loss: 0.21858814358711243, Accuracy: 95.0\n",
      "Iterations: 3000, Loss: 0.22211824357509613, Accuracy: 96.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as dsets\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "'''\n",
    "STEP 1: LOAD DATASET\n",
    "'''\n",
    "train_dataset = dsets.MNIST(root = './data',\n",
    "                            train = True,\n",
    "                            transform = transforms.ToTensor(),\n",
    "                            download = True)\n",
    "\n",
    "test_dataset = dsets.MNIST(root = './data',\n",
    "                           train = False,\n",
    "                           transform = transforms.ToTensor())\n",
    "\n",
    "\n",
    "'''\n",
    "STEP 2: MAKE SATASET ITERABLE\n",
    "'''\n",
    "batch_size = 100\n",
    "n_iters = 3000\n",
    "\n",
    "num_epochs = n_iters / (len(train_dataset) / batch_size)\n",
    "num_epochs = int(num_epochs)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                           batch_size=batch_size,\n",
    "                                           shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                        batch_size=batch_size,\n",
    "                                        shuffle=False)\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "STEP 3: CREATE MODEL CLASS\n",
    "'''\n",
    "class RNNModel(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_dim, hidden_dim, layer_dim, output_dim):\n",
    "        super(RNNModel, self).__init__()\n",
    "        # Hidden Dimensions\n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "        # Number of hidden layers\n",
    "        self.layer_dim = layer_dim\n",
    "        \n",
    "        # Building your RNN\n",
    "        # batch_first = True causes input/output tensors to be of shape\n",
    "        # (batch_dim, seq_dim, input_dim)\n",
    "        self.rnn = nn.RNN(input_dim, hidden_dim, layer_dim, batch_first=True, nonlinearity = 'tanh')\n",
    "        \n",
    "        # Readout layer\n",
    "        self.fn = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Initialize hidden state with zeroes\n",
    "        if torch.cuda.is_available():\n",
    "            h0 = Variable(torch.zeros(self.layer_dim, x.size(0), self.hidden_dim).cuda())\n",
    "        else:\n",
    "            h0 = Variable(torch.zeros(self.layer_dim, x.size(0), self.hidden_dim).cuda())\n",
    "        \n",
    "        # One time-step\n",
    "        out, hn = self.rnn(x, h0)\n",
    "        \n",
    "        # Input hidden state of the last time step\n",
    "        # out.size() ---> 100, 28, 100\n",
    "        # out[:, -1, :] ---> 100, 100 ---> just want last time step hidden states!\n",
    "        out = self.fn(out[:, -1, :])\n",
    "        # out.size() ---> 100, 10 \n",
    "        return out\n",
    "   \n",
    "\n",
    "\n",
    "'''\n",
    "STEP 4: INSTANTIATE MODEL CLASS\n",
    "'''\n",
    "input_dim = 28\n",
    "hidden_dim = 100\n",
    "layer_dim = 2\n",
    "output_dim = 10\n",
    "\n",
    "model = RNNModel(input_dim, hidden_dim, layer_dim, output_dim)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    model.cuda()\n",
    "\n",
    "# PRINTING MODEL AND PARAMETERS\n",
    "print(model)\n",
    "print('-'*60)\n",
    "print(len(list(model.parameters())))\n",
    "for i in range(len(list(model.parameters()))):\n",
    "    print(list(model.parameters())[i].size())\n",
    "print('-'*60)\n",
    "\n",
    "\n",
    "'''\n",
    "STEP 5: INSTANTIATE LOSS CLASS\n",
    "'''\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "'''\n",
    "STEP 6: INSTANTIATE OPTIMIZER CLASS\n",
    "'''\n",
    "learning_rate = 0.1\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "STEP 7: TRAIN THE MODEL\n",
    "'''\n",
    "# Number of steps to unroll\\\n",
    "seq_dim = 28\n",
    "iter = 0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        if torch.cuda.is_available():\n",
    "            images = Variable(images.view(-1, seq_dim, input_dim).cuda())\n",
    "            labels = Variable(labels.cuda())\n",
    "        else:\n",
    "            images = Variable(images.view(-1, seq_dim, input_dim))\n",
    "            labels = Variable(labels)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = model(images)\n",
    "        \n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        iter += 1\n",
    "        \n",
    "        if iter % 500 == 0:\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            \n",
    "            for images, labels in test_loader:\n",
    "                if torch.cuda.is_available():\n",
    "                    images = Variable(images.view(-1, seq_dim, input_dim).cuda())\n",
    "                else:\n",
    "                    images = Variable(images.view(-1, seq_dim, input_dim))\n",
    "                outputs = model(images)\n",
    "                \n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                \n",
    "                total += labels.size(0)\n",
    "                if torch.cuda.is_available():\n",
    "                    correct += (predicted.cpu() == labels.cpu()).sum()\n",
    "                else:\n",
    "                    correct += (predicted == labels).sum()\n",
    "                \n",
    "            accuracy = 100 * correct / total\n",
    "            \n",
    "            print('Iterations: {}, Loss: {}, Accuracy: {}'.format(iter, loss.data, accuracy.float()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model = True\n",
    "if save_model is True:\n",
    "    # saving only params\n",
    "    torch.save(model.state_dict(), 'Models/RNNPytorch.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
